install.packages("mxnet")
l = c(null,9,1)
l = c(na,9,1)
l = c(NULL,9,1)
l
is.na(l)
l = c(NA,9,1)
is.na(l)
example(group_by)
install.packages("dply")
install.packages("dplyr")
library(dplyr)
install.packages("dplyr")
install.packages("dplyr")
source('C:/Users/pecu6/OneDrive/文件/GitHub/kaggledata/used-car.R', encoding = 'UTF-8', echo=TRUE)
install.packages(dplyr)
install.packages("dplyr")
install.packages("dplyr")
source('C:/Users/pecu6/OneDrive/文件/GitHub/kaggledata/used-car.R', encoding = 'UTF-8', echo=TRUE)
install.packages("tidyverse")
install.packages("C:/Users/pecu6/Desktop/tidyverse_1.1.1.zip", repos = NULL, type = "win.binary")
source('C:/Users/pecu6/OneDrive/文件/GitHub/kaggledata/used-car.R', encoding = 'UTF-8', echo=TRUE)
source('C:/Users/pecu6/OneDrive/文件/GitHub/kaggledata/used-car.R', encoding = 'UTF-8', echo=TRUE)
install.packages("C:/Users/pecu6/Desktop/tidyverse_1.1.1.zip", repos = NULL, type = "win.binary")
source('C:/Users/pecu6/OneDrive/文件/GitHub/kaggledata/used-car.R', encoding = 'UTF-8', echo=TRUE)
source('C:/Users/pecu6/OneDrive/文件/GitHub/kaggledata/used-car.R', encoding = 'UTF-8', echo=TRUE)
install.packages("dplyr")
source('C:/Users/pecu6/OneDrive/文件/GitHub/kaggledata/used-car.R', encoding = 'UTF-8', echo=TRUE)
install.packages("rcpp")
install.packages("Rcpp")
source('C:/Users/pecu6/OneDrive/文件/GitHub/kaggledata/used-car.R', encoding = 'UTF-8', echo=TRUE)
source('C:/Users/pecu6/OneDrive/文件/GitHub/kaggledata/used-car.R', encoding = 'UTF-8', echo=TRUE)
install.packages("Rcpp")
source('C:/Users/pecu6/Desktop/teacher.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/teacher.r', echo=TRUE)
sd(c(0,100))
sd(c(50,50))
load(url("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/ESL.mixture.rda"))
names(ESL.mixture)
rm(x, y)
attach(ESL.mixture)
plot(x, col = y + 1)
source('C:/Users/pecu6/Desktop/Word2Vec/SVM.R', echo=TRUE)
plot(x, col = y + 1)
dat = data.frame(y = factor(y), x)
fit = svm(factor(y) ~ ., data = dat, scale = FALSE, kernel = "radial", cost = 5)
xgrid = expand.grid(X1 = px1, X2 = px2)
ygrid = predict(fit, xgrid)
plot(xgrid, col = as.numeric(ygrid), pch = 20, cex = 0.2)
points(x, col = y + 1, pch = 19)
func = predict(fit, xgrid, decision.values = TRUE)
func = attributes(func)$decision
xgrid = expand.grid(X1 = px1, X2 = px2)
ygrid = predict(fit, xgrid)
plot(xgrid, col = as.numeric(ygrid), pch = 20, cex = 0.2)
points(x, col = y + 1, pch = 19)
contour(px1, px2, matrix(func, 69, 99), level = 0, add = TRUE)
contour(px1, px2, matrix(prob, 69, 99), level = 0.5, add = TRUE, col = "blue",
lwd = 2)
ESL.mixture[1]
load(url("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/ESL.mixture.rda"))
names(ESL.mixture)
rm(x, y)
attach(ESL.mixture)
load(url("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/ESL.mixture.rda"))
names(ESL.mixture)
rm(x, y)
attach(ESL.mixture)
plot(x, col = y + 1)
dat = data.frame(y = factor(y), x)
View(dat)
fit = svm(factor(y) ~ ., data = dat, scale = FALSE, kernel = "radial", cost = 5)
xgrid = expand.grid(X1 = px1, X2 = px2)
ygrid = predict(fit, xgrid)
plot(xgrid, col = as.numeric(ygrid), pch = 20, cex = 0.2)
points(x, col = y + 1, pch = 19)
func = predict(fit, xgrid, decision.values = TRUE)
func = attributes(func)$decision
xgrid = expand.grid(X1 = px1, X2 = px2)
ygrid = predict(fit, xgrid)
plot(xgrid, col = as.numeric(ygrid), pch = 20, cex = 0.2)
points(x, col = y + 1, pch = 19)
contour(px1, px2, matrix(func, 69, 99), level = 0, add = TRUE)
contour(px1, px2, matrix(prob, 69, 99), level = 0.5, add = TRUE, col = "blue",
lwd = 2)
source('~/.active-rstudio-document', echo=TRUE)
Viewer()
View()
library(httr)
GET("http://www.google.com.tw")
chickwts
head(chickwts)
class(chickwts$feed)
table(chickwts$feed)
data(Chile, package = "car")
x <- c(0,1,2,3,5,8,13,21,34)
mean(x)
median(x)
sd(x)
var(x)
y <- log(x + 1)
cor(x,y)
x <- c(x, NA)
x
mean(x)
dframe
mean(iris)
iris
cars
mean(cars)
class(cars)
mean(cars)
mean(cars$speed
)
mean(cars[,1:2])
mean(cars)
var -> "a\b"
var
var -> "a\\b"
var
print(var)
var -> "a\\\\b"
print(var)
var <- "a\\b"
writeLines(var)
install.packages("stringr")
library(hflights)
install.packages("hflights")
library(hflights)
class(hflights)
?tbl_df
library(hflights)
library(dplyr)
class(hflights)
?tbl_df
tbl_df(hflights)
temp <- tbl_df(hflights)
View(temp)
org <- hflights
View(org)
knitr::opts_chunk$set(echo = TRUE)
#Converting the description data to text
description_data_100 <- html_text(description_data_html_100)
install.packages("xml2")
#Converting the description data to text
description_data_100 <- html_text(description_data_html_100)
#Converting the description data to text
description_data_100 <- html_text(description_data_html_100)
library('rvest')
library('NLP')
library('tm')
library('stringr')
library('wordcloud')
library('RColorBrewer')
library('xml2')
library('rvest')
library('NLP')
library('tm')
library('stringr')
library('RColorBrewer')
library('wordcloud')
library('xml2')
knitr::opts_chunk$set(echo = TRUE)
library('rvest')
library('NLP')
library('tm')
library('stringr')
library('RColorBrewer')
library('wordcloud')
library('xml2')
#Converting the description data to text
description_data_100 <- html_text(description_data_html_100)
install.packages('xml2')
install.packages('rvest')
install.packages('NLP')
install.packages('tm')
install.packages('stringr')
install.packages('wordcloud')
install.packages('RColorBrewer')
install.packages("xml2")
install.packages("tm")
knitr::opts_chunk$set(echo = TRUE)
install.packages('xml2')
install.packages('rvest')
install.packages('NLP')
install.packages('tm')
install.packages('stringr')
install.packages('wordcloud')
install.packages('RColorBrewer')
install.packages('xml2')
install.packages('rvest')
install.packages('NLP')
install.packages('tm')
install.packages('stringr')
install.packages('wordcloud')
install.packages('RColorBrewer')
library('xml2')
library('rvest')
library('NLP')
library('tm')
library('stringr')
library('RColorBrewer')
library('wordcloud')
#Specifying the url for desired website to be scrapped
url_100 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=1&ref_=adv_nxt'
url_200 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=2&ref_=adv_nxt'
url_300 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=3&ref_=adv_nxt'
url_400 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=4&ref_=adv_nxt'
url_500 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=5&ref_=adv_nxt'
#Reading the HTML code from the website
webpage_100 <- read_html(url_100)
webpage_200 <- read_html(url_200)
webpage_300 <- read_html(url_300)
webpage_400 <- read_html(url_400)
webpage_500 <- read_html(url_500)
#Using CSS selectors to scrap the description section
description_data_html_100 <- html_nodes(webpage_100,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
description_data_html_200 <- html_nodes(webpage_200,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
description_data_html_300 <- html_nodes(webpage_300,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
description_data_html_400 <- html_nodes(webpage_400,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
description_data_html_500 <- html_nodes(webpage_500,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
knitr::opts_chunk$set(echo = TRUE)
library('xml2')
library('rvest')
library('NLP')
library('tm')
library('stringr')
library('RColorBrewer')
library('wordcloud')
#Converting the description data to text
description_data_100 <- html_text(description_data_html_100)
knitr::opts_chunk$set(echo = TRUE)
library('xml2')
library('rvest')
library('NLP')
library('tm')
library('stringr')
library('RColorBrewer')
library('wordcloud')
#Converting the description data to text
description_data_100 <- html_text(description_data_html_100)
knitr::opts_chunk$set(echo = TRUE)
library('xml2')
library('rvest')
library('NLP')
library('tm')
library('stringr')
library('RColorBrewer')
library('wordcloud')
#Converting the description data to text
description_data_100 <- html_text(description_data_html_100)
knitr::opts_chunk$set(echo = TRUE)
library('xml2')
library('rvest')
library('NLP')
library('tm')
library('stringr')
library('RColorBrewer')
library('wordcloud')
#Specifying the url for desired website to be scrapped
url_100 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=1&ref_=adv_nxt'
url_200 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=2&ref_=adv_nxt'
url_300 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=3&ref_=adv_nxt'
url_400 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=4&ref_=adv_nxt'
url_500 <- 'http://www.imdb.com/search/title?count=100&release_date=2017,2017&title_type=feature&page=5&ref_=adv_nxt'
#Reading the HTML code from the website
webpage_100 <- read_html(url_100)
webpage_200 <- read_html(url_200)
webpage_300 <- read_html(url_300)
webpage_400 <- read_html(url_400)
webpage_500 <- read_html(url_500)
#Using CSS selectors to scrap the description section
description_data_html_100 <- html_nodes(webpage_100,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
description_data_html_200 <- html_nodes(webpage_200,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
description_data_html_300 <- html_nodes(webpage_300,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
description_data_html_400 <- html_nodes(webpage_400,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
description_data_html_500 <- html_nodes(webpage_500,'.text-muted+ .text-muted , .ratings-bar+ .text-muted')
#Converting the description data to text
description_data_100 <- html_text(description_data_html_100)
description_data_200 <- html_text(description_data_html_200)
description_data_300 <- html_text(description_data_html_300)
description_data_400 <- html_text(description_data_html_400)
description_data_500 <- html_text(description_data_html_500)
#Combine char strings
description_data <- paste(description_data_100, description_data_200, description_data_300, description_data_400, description_data_500, sep = " ")
#Let's have a look at the description
head(description_data)
#Combine as one string
description_data <- paste(description_data, collapse = " ")
#Data-Preprocessing: removing '\n'
description_data2 <- gsub("\n","",description_data)
#Data-Preprocessing: removing non-words
description_data2 <- gsub("\\W"," ",description_data2)
#Data-Preprocessing: removing digits
description_data2 <- gsub("\\d"," ",description_data2)
#Data-Preprocessing: changing all to lower case
description_data2 <- tolower(description_data2)
#Data-Preprocessing: removing stopwords
description_data2 <- removeWords(description_data2,stopwords())
#Data-Preprocessing: removing single letters
description_data2 <- gsub("\\b[A-z]\\b{1}"," ",description_data2)
#Data-Preprocessing: removing irrelevant words
description_data2 <- gsub("see"," ",description_data2)
description_data2 <- gsub("full"," ",description_data2)
description_data2 <- gsub("summary"," ",description_data2)
#Data-Preprocessing: removing whitespaces
description_data2 <- stripWhitespace(description_data2)
#Data-Preprocessing: split up processed string into a list of separate words
textbag <- str_split(description_data2, "\\s+")
#Data-Preprocessing: unlist textbag into separate characters
textbag <- unlist(textbag)
wordcloud(textbag, min.freq = 10, random.order = FALSE, scale=c(5, 0.5), color=brewer.pal(6, "Dark2"))
head
View(head)
View(Userhead)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
View(Userhead)
Userhead
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
res$content
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
View(getResult)
res$content
getResult = content(res$content)
getResult = res %>% content()
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
View(getResult)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', encoding = 'UTF-8', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
res = GET(url=Myurl, headers = Userhead)
getResult = content(res)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
res
res$headers
res$all_headers
header(res)
res = GET(url=Myurl)
res
res$handle
res$all_headers
GET("http://httpbin.org/user-agent")
GET("https://buy.yungching.com.tw/region/%E5%8F%B0%E5%8C%97%E5%B8%82-_c/")
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', encoding = 'UTF-8', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
View(getResult)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
getResult[1]
getResult[1]$node
getResult[2]
getResult[2]$doc
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
? html
html
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
res
res$content
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
getResult
library(rjson)
jsonData = fromJSON(getResult)
library(XML)
doc = htmlParse(getResult)
doc
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
doc
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
doc
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
data
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
data
data[1]
print(data[1])
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
text
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
text
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
text
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
source('C:/Users/pecu6/Desktop/house.r', echo=TRUE)
View(result)
source('C:/Users/pecu6/Desktop/getTest.R', echo=TRUE)
source('C:/Users/pecu6/Desktop/getTest.R', echo=TRUE)
source('C:/Users/pecu6/Desktop/getTest.R', echo=TRUE)
post$posts
source('C:/Users/pecu6/Desktop/kmeans.R', echo=TRUE)
source('C:/Users/pecu6/Desktop/kmeans.R', echo=TRUE)
attitude
source('C:/Users/pecu6/Desktop/kmeans.R', echo=TRUE)
View(dat)
source('C:/Users/pecu6/Desktop/kmeans.R', echo=TRUE)
View(dat)
source('C:/Users/pecu6/Desktop/kmeans.R', echo=TRUE)
source('C:/Users/pecu6/Desktop/kmeans.R', echo=TRUE)
source('C:/Users/pecu6/Desktop/kmeans.R', echo=TRUE)
source('C:/Users/pecu6/Desktop/kmeans.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
View(x)
y
round(log(0.94))
round(log(1.94))
round(log(2.94))
round(0.94)
round(1.94)
library(NLP)
library(tm)
library(proxy)
library(dplyr)
library(NLP)
library(tm)
library(proxy)
library(stats)
library(dplyr)
datasets::cars
datasets::AirPassengers
datasets::CO2
datasets::women
datasets::BOD
datasets::iris
datasets::ChickWeight
class(datasets::ChickWeight)
a = datasets::ChickWeight
View(a)
class(a$Diet)
ChickWeight
summary(ChickWeight )
setwd("C:/Users/pecu6/Desktop/myFunctions")
